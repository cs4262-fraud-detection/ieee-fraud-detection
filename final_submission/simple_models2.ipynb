{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import decomposition\n",
    "\n",
    "from sklearn import preprocessing, decomposition, model_selection, linear_model, metrics, ensemble, svm, utils\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "train_transaction = pd.read_csv('../data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('../data/train_identity.csv')\n",
    "# test_transaction = pd.read_csv('../data/test_transaction.csv')\n",
    "# test_identity = pd.read_csv('../data/test_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (590540, 435)\n"
     ]
    }
   ],
   "source": [
    "# Join datasets\n",
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "# test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(f'Shape of train set: {train.shape}')\n",
    "# print(f'Shape of test set: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce memory usage\n",
    "def reduce_mem(df):\n",
    "  start_mem=df.memory_usage().sum()/1024**2\n",
    "  print('Initial Memory Usage : {:.2f} MB'.format(start_mem))\n",
    "  for col in df.columns:\n",
    "    col_type=df[col].dtype\n",
    "    if col_type != object:\n",
    "      mn, mx = df[col].min(), df[col].max()\n",
    "      if str(col_type)[:3]=='int':\n",
    "        if mn>np.iinfo(np.int8).min and mx<np.iinfo(np.int8).max:\n",
    "          df[col]=df[col].astype(np.int8)\n",
    "        elif mn>np.iinfo(np.int16).min and mx<np.iinfo(np.int16).max:\n",
    "          df[col]=df[col].astype(np.int16)\n",
    "        elif mn>np.iinfo(np.int32).min and mx<np.iinfo(np.int32).max:\n",
    "          df[col]=df[col].astype(np.int32)\n",
    "      else:\n",
    "        if mn>np.finfo(np.float16).min and mx<np.finfo(np.float16).max:\n",
    "          df[col]=df[col].astype(np.float16)\n",
    "        elif mn>np.finfo(np.float32).min and mx<np.finfo(np.float32).max:\n",
    "          df[col]=df[col].astype(np.float32)\n",
    "  end_mem = df.memory_usage().sum()/1024**2\n",
    "  print('Final Memory Usage : {:.2f} MB'.format(end_mem))\n",
    "  print('Decreased by {:.2f}%'.format(100*(start_mem-end_mem)/start_mem))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Memory Usage : 1959.88 MB\n",
      "Final Memory Usage : 648.22 MB\n",
      "Decreased by 66.93%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del train_transaction, train_identity, test_transaction, test_identity\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Target distribution')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['isFraud']) #Imbalanced Dataset\n",
    "plt.title('Target distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569877\n",
      "20663\n"
     ]
    }
   ],
   "source": [
    "not_fraud = train[train.isFraud==0]\n",
    "fraud = train[train.isFraud==1]\n",
    "\n",
    "print(len(not_fraud))\n",
    "print(len(fraud))\n",
    "\n",
    "# Downsample the data and re-concatenate\n",
    "not_fraud_downsampled = utils.resample(not_fraud, replace=False, n_samples = len(fraud), random_state = 27) \n",
    "train = pd.concat([not_fraud_downsampled, fraud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20663\n",
      "20663\n"
     ]
    }
   ],
   "source": [
    "not_fraud = train[train.isFraud==0]\n",
    "fraud = train[train.isFraud==1]\n",
    "\n",
    "print(len(not_fraud))\n",
    "print(len(fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['isFraud'].values\n",
    "\n",
    "train = train.drop('isFraud', axis=1)\n",
    "# test = test.copy()\n",
    "\n",
    "# Delete rows with more than 70%? of NaNs, and fill out the rest with some value\n",
    "train = train.fillna(-1)\n",
    "# test = test.fillna(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding\n",
    "for f in train.columns:\n",
    "    if train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "#       lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        lbl.fit(list(train[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "#       test[f] = lbl.transform(list(test[f].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler() # MinMaxScaler StandardScaler RobustScaler\n",
    "cols = list(train.columns)\n",
    "train[cols] = scaler.fit_transform(train[cols])\n",
    "# test[cols] = scaler.transform(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "N = 50\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "# svd_param_grid = {'n_components':[25, 50, 100, 200], 'n_iters':[5, 10, 15, 20]}\n",
    "svd = decomposition.TruncatedSVD(n_components=N)\n",
    "# svd_gs = GridSearchCV(svd, svd_param_grid, cv=10)\n",
    "# svd_gs.fit(train[cols], y, scoring=scoring)\n",
    "# sorted(svd_gs.cv_results_.keys())\n",
    "\n",
    "X = svd.fit_transform(train[cols], y) \n",
    "# svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>41321</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.276083</td>\n",
       "      <td>-2.431949</td>\n",
       "      <td>0.646814</td>\n",
       "      <td>2.808476</td>\n",
       "      <td>0.640184</td>\n",
       "      <td>-1.751661</td>\n",
       "      <td>-0.016849</td>\n",
       "      <td>-1.261922</td>\n",
       "      <td>-1.436864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282639</td>\n",
       "      <td>0.460544</td>\n",
       "      <td>0.366965</td>\n",
       "      <td>-0.524417</td>\n",
       "      <td>1.839353</td>\n",
       "      <td>-0.418180</td>\n",
       "      <td>0.365184</td>\n",
       "      <td>-0.037096</td>\n",
       "      <td>-0.405702</td>\n",
       "      <td>-0.687012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41322</td>\n",
       "      <td>1</td>\n",
       "      <td>2.318632</td>\n",
       "      <td>10.555326</td>\n",
       "      <td>-0.078963</td>\n",
       "      <td>1.527928</td>\n",
       "      <td>-2.989022</td>\n",
       "      <td>3.220783</td>\n",
       "      <td>0.316242</td>\n",
       "      <td>0.116696</td>\n",
       "      <td>-0.251243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350644</td>\n",
       "      <td>0.528664</td>\n",
       "      <td>-0.424586</td>\n",
       "      <td>0.626786</td>\n",
       "      <td>0.363555</td>\n",
       "      <td>-0.411206</td>\n",
       "      <td>0.186528</td>\n",
       "      <td>0.131911</td>\n",
       "      <td>-0.509930</td>\n",
       "      <td>0.197590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41323</td>\n",
       "      <td>1</td>\n",
       "      <td>11.628858</td>\n",
       "      <td>-9.553840</td>\n",
       "      <td>-4.769135</td>\n",
       "      <td>4.146200</td>\n",
       "      <td>-3.481114</td>\n",
       "      <td>-0.330705</td>\n",
       "      <td>0.287055</td>\n",
       "      <td>0.696677</td>\n",
       "      <td>2.840569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383455</td>\n",
       "      <td>-0.121058</td>\n",
       "      <td>0.520722</td>\n",
       "      <td>0.794682</td>\n",
       "      <td>0.099625</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>0.920780</td>\n",
       "      <td>-0.772701</td>\n",
       "      <td>-0.231387</td>\n",
       "      <td>-0.352067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41324</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.882393</td>\n",
       "      <td>-2.129048</td>\n",
       "      <td>0.552940</td>\n",
       "      <td>2.688539</td>\n",
       "      <td>0.281518</td>\n",
       "      <td>-1.189546</td>\n",
       "      <td>-0.038160</td>\n",
       "      <td>-1.069363</td>\n",
       "      <td>-1.323501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037803</td>\n",
       "      <td>0.149278</td>\n",
       "      <td>0.191911</td>\n",
       "      <td>-0.419619</td>\n",
       "      <td>0.758227</td>\n",
       "      <td>-0.517669</td>\n",
       "      <td>0.885403</td>\n",
       "      <td>0.024368</td>\n",
       "      <td>0.292841</td>\n",
       "      <td>-0.106673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41325</td>\n",
       "      <td>1</td>\n",
       "      <td>11.483212</td>\n",
       "      <td>-9.626314</td>\n",
       "      <td>-4.782605</td>\n",
       "      <td>4.151696</td>\n",
       "      <td>-3.411102</td>\n",
       "      <td>-0.400051</td>\n",
       "      <td>0.255108</td>\n",
       "      <td>0.662173</td>\n",
       "      <td>2.815608</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656035</td>\n",
       "      <td>0.612073</td>\n",
       "      <td>0.095638</td>\n",
       "      <td>0.453482</td>\n",
       "      <td>0.674314</td>\n",
       "      <td>-0.207302</td>\n",
       "      <td>0.857066</td>\n",
       "      <td>-1.025328</td>\n",
       "      <td>-0.405222</td>\n",
       "      <td>-0.379437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       isFraud          0          1         2         3         4         5  \\\n",
       "41321        1  -7.276083  -2.431949  0.646814  2.808476  0.640184 -1.751661   \n",
       "41322        1   2.318632  10.555326 -0.078963  1.527928 -2.989022  3.220783   \n",
       "41323        1  11.628858  -9.553840 -4.769135  4.146200 -3.481114 -0.330705   \n",
       "41324        1  -6.882393  -2.129048  0.552940  2.688539  0.281518 -1.189546   \n",
       "41325        1  11.483212  -9.626314 -4.782605  4.151696 -3.411102 -0.400051   \n",
       "\n",
       "              6         7         8  ...        40        41        42  \\\n",
       "41321 -0.016849 -1.261922 -1.436864  ...  0.282639  0.460544  0.366965   \n",
       "41322  0.316242  0.116696 -0.251243  ... -0.350644  0.528664 -0.424586   \n",
       "41323  0.287055  0.696677  2.840569  ... -0.383455 -0.121058  0.520722   \n",
       "41324 -0.038160 -1.069363 -1.323501  ... -0.037803  0.149278  0.191911   \n",
       "41325  0.255108  0.662173  2.815608  ...  1.656035  0.612073  0.095638   \n",
       "\n",
       "             43        44        45        46        47        48        49  \n",
       "41321 -0.524417  1.839353 -0.418180  0.365184 -0.037096 -0.405702 -0.687012  \n",
       "41322  0.626786  0.363555 -0.411206  0.186528  0.131911 -0.509930  0.197590  \n",
       "41323  0.794682  0.099625 -0.061522  0.920780 -0.772701 -0.231387 -0.352067  \n",
       "41324 -0.419619  0.758227 -0.517669  0.885403  0.024368  0.292841 -0.106673  \n",
       "41325  0.453482  0.674314 -0.207302  0.857066 -1.025328 -0.405222 -0.379437  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"isFraud\"] = y\n",
    "\n",
    "for i in range(50):\n",
    "    df[i] = X[:,i]\n",
    "    \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = model_selection.train_test_split(df.drop('isFraud',axis=1), y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      4169\n",
      "           1       0.81      0.78      0.79      4097\n",
      "\n",
      "    accuracy                           0.80      8266\n",
      "   macro avg       0.80      0.80      0.80      8266\n",
      "weighted avg       0.80      0.80      0.80      8266\n",
      "\n",
      "CPU times: user 1min 4s, sys: 205 ms, total: 1min 4s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "arch = \"reg\"\n",
    "\n",
    "lr_param_grid = {}\n",
    "rfc_param_grid = {'n_estimators':[150, 200, 250], 'criterion':('gini', 'entropy')}\n",
    "svc_param_grid = {}\n",
    "\n",
    "#reg = linear_model.LogisticRegression(C=1, solver=\"newton-cg\", penalty=\"l2\", n_jobs=-1, max_iter=200).fit(X_train, y_train) \n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=200,criterion='gini',n_jobs=-1).fit(X_train, y_train)\n",
    "# rfc = ensemble.RandomForestClassifier(max_iter=200, n_jobs=-1)\n",
    "# rfc_gs = GridSearchCV(rfc, rfc_param_grid, cv=10)\n",
    "# rfc_gs.fit(X_train, y_train)\n",
    "#reg = svm.SVC(max_iter=200).fit(X_train, y_train)\n",
    "# try gaussianNB()\n",
    "\n",
    "y_pred = rfc.predict_proba(X_test)\n",
    "# print(y_test)\n",
    "# print(y_pred)\n",
    "print(metrics.classification_report(y_test, [round(y[1]) for y in y_pred]))\n",
    "# sorted(rfc_gs.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_with_PCA(k, x_tr, y_tr):\n",
    "    svd = decomposition.TruncatedSVD(n_components=k)\n",
    "    X = svd.fit_transform(x_tr, y_tr) \n",
    "    df = pd.DataFrame()\n",
    "    df[\"isFraud\"] = y\n",
    "    for i in range(k):\n",
    "        df[i] = X[:,i]   \n",
    "    return model_selection.train_test_split(df.drop('isFraud',axis=1), y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=50\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 28060 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "28060/28060 [==============================] - 3s 102us/sample - loss: 0.6160 - accuracy: 0.6640 - categorical_accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.7286 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "28060/28060 [==============================] - 1s 53us/sample - loss: 0.5473 - accuracy: 0.7249 - categorical_accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.7404 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28060/28060 [==============================] - 1s 53us/sample - loss: 0.5280 - accuracy: 0.7382 - categorical_accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.7460 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28060/28060 [==============================] - 1s 53us/sample - loss: 0.5198 - accuracy: 0.7424 - categorical_accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.7526 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.5086 - accuracy: 0.7486 - categorical_accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.7550 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.5030 - accuracy: 0.7498 - categorical_accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.7554 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.4968 - accuracy: 0.7523 - categorical_accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.7536 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28060/28060 [==============================] - 2s 56us/sample - loss: 0.4941 - accuracy: 0.7560 - categorical_accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.7556 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28060/28060 [==============================] - 2s 56us/sample - loss: 0.4934 - accuracy: 0.7571 - categorical_accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.7606 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28060/28060 [==============================] - 2s 62us/sample - loss: 0.4873 - accuracy: 0.7622 - categorical_accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.7604 - val_categorical_accuracy: 1.0000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "test loss, test acc, categorical accuracy: [0.48098580571314686, 0.763489, 1.0]\n",
      "For k=75\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 28060 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "28060/28060 [==============================] - 3s 100us/sample - loss: 0.6310 - accuracy: 0.6459 - categorical_accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.7266 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "28060/28060 [==============================] - 2s 54us/sample - loss: 0.5564 - accuracy: 0.7242 - categorical_accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.7386 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.5345 - accuracy: 0.7375 - categorical_accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7416 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.5202 - accuracy: 0.7430 - categorical_accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.7478 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.5067 - accuracy: 0.7492 - categorical_accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.7524 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.4975 - accuracy: 0.7559 - categorical_accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.7532 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28060/28060 [==============================] - 2s 60us/sample - loss: 0.4889 - accuracy: 0.7584 - categorical_accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.7618 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.4875 - accuracy: 0.7606 - categorical_accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.7654 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28060/28060 [==============================] - 2s 56us/sample - loss: 0.4817 - accuracy: 0.7661 - categorical_accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.7694 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.4749 - accuracy: 0.7702 - categorical_accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.7698 - val_categorical_accuracy: 1.0000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "test loss, test acc, categorical accuracy: [0.4706596653613749, 0.7697798, 1.0]\n",
      "For k=100\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 28060 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "28060/28060 [==============================] - 3s 100us/sample - loss: 0.6585 - accuracy: 0.6255 - categorical_accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.7176 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.5643 - accuracy: 0.7106 - categorical_accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.7328 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.5358 - accuracy: 0.7329 - categorical_accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7398 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.5162 - accuracy: 0.7451 - categorical_accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.7438 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28060/28060 [==============================] - 2s 60us/sample - loss: 0.5054 - accuracy: 0.7498 - categorical_accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.7530 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4958 - accuracy: 0.7548 - categorical_accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.7594 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.4897 - accuracy: 0.7613 - categorical_accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.7688 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4805 - accuracy: 0.7649 - categorical_accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.7740 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4758 - accuracy: 0.7707 - categorical_accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.7796 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4701 - accuracy: 0.7754 - categorical_accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.7810 - val_categorical_accuracy: 1.0000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "test loss, test acc, categorical accuracy: [0.46598324994472107, 0.7764336, 1.0]\n",
      "For k=125\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 28060 samples, validate on 5000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28060/28060 [==============================] - 3s 104us/sample - loss: 0.6476 - accuracy: 0.6372 - categorical_accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.7098 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.5586 - accuracy: 0.7141 - categorical_accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.7336 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28060/28060 [==============================] - 2s 56us/sample - loss: 0.5317 - accuracy: 0.7389 - categorical_accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.7422 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.5109 - accuracy: 0.7496 - categorical_accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.7536 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4986 - accuracy: 0.7551 - categorical_accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.7566 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4873 - accuracy: 0.7636 - categorical_accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.7714 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4804 - accuracy: 0.7701 - categorical_accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.7730 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4746 - accuracy: 0.7748 - categorical_accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.7704 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4676 - accuracy: 0.7794 - categorical_accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.7756 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.4637 - accuracy: 0.7797 - categorical_accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.7738 - val_categorical_accuracy: 1.0000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "test loss, test acc, categorical accuracy: [0.45979265753651194, 0.77945805, 1.0]\n",
      "For k=150\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 28060 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "28060/28060 [==============================] - 3s 102us/sample - loss: 0.6954 - accuracy: 0.6020 - categorical_accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.6852 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "28060/28060 [==============================] - 2s 56us/sample - loss: 0.5808 - accuracy: 0.6948 - categorical_accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.7330 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28060/28060 [==============================] - 2s 55us/sample - loss: 0.5415 - accuracy: 0.7287 - categorical_accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.7448 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28060/28060 [==============================] - 2s 56us/sample - loss: 0.5215 - accuracy: 0.7435 - categorical_accuracy: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.7534 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.5056 - accuracy: 0.7546 - categorical_accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.7614 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4921 - accuracy: 0.7636 - categorical_accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.7668 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4843 - accuracy: 0.7692 - categorical_accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.7698 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4751 - accuracy: 0.7752 - categorical_accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.7716 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28060/28060 [==============================] - 2s 58us/sample - loss: 0.4706 - accuracy: 0.7780 - categorical_accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.7744 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4608 - accuracy: 0.7849 - categorical_accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.7750 - val_categorical_accuracy: 1.0000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "test loss, test acc, categorical accuracy: [0.46140606167412773, 0.7809098, 1.0]\n",
      "For k=175\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 28060 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "28060/28060 [==============================] - 4s 143us/sample - loss: 0.6212 - accuracy: 0.6526 - categorical_accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.7238 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "28060/28060 [==============================] - 2s 61us/sample - loss: 0.5404 - accuracy: 0.7299 - categorical_accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.7458 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.5145 - accuracy: 0.7504 - categorical_accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.7598 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28060/28060 [==============================] - 2s 68us/sample - loss: 0.4949 - accuracy: 0.7605 - categorical_accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.7664 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28060/28060 [==============================] - 3s 119us/sample - loss: 0.4826 - accuracy: 0.7665 - categorical_accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.7678 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28060/28060 [==============================] - 2s 64us/sample - loss: 0.4717 - accuracy: 0.7775 - categorical_accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.7718 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28060/28060 [==============================] - 2s 64us/sample - loss: 0.4679 - accuracy: 0.7789 - categorical_accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.7754 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28060/28060 [==============================] - 2s 67us/sample - loss: 0.4601 - accuracy: 0.7832 - categorical_accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.7738 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28060/28060 [==============================] - 2s 68us/sample - loss: 0.4562 - accuracy: 0.7872 - categorical_accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.7746 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28060/28060 [==============================] - 2s 64us/sample - loss: 0.4507 - accuracy: 0.7911 - categorical_accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.7792 - val_categorical_accuracy: 1.0000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "test loss, test acc, categorical accuracy: [0.4520669112461057, 0.78623277, 1.0]\n",
      "For k=200\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 28060 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "28060/28060 [==============================] - 3s 108us/sample - loss: 0.6387 - accuracy: 0.6372 - categorical_accuracy: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.7052 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28060/28060 [==============================] - 2s 66us/sample - loss: 0.5518 - accuracy: 0.7189 - categorical_accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.7388 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.5245 - accuracy: 0.7388 - categorical_accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.7508 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.5019 - accuracy: 0.7527 - categorical_accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.7594 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "28060/28060 [==============================] - 2s 57us/sample - loss: 0.4868 - accuracy: 0.7653 - categorical_accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.7698 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4755 - accuracy: 0.7702 - categorical_accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.7762 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4689 - accuracy: 0.7768 - categorical_accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.7782 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4619 - accuracy: 0.7822 - categorical_accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.7824 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4572 - accuracy: 0.7848 - categorical_accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.7874 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28060/28060 [==============================] - 2s 59us/sample - loss: 0.4508 - accuracy: 0.7875 - categorical_accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.7880 - val_categorical_accuracy: 1.0000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "test loss, test acc, categorical accuracy: [0.45284044135433116, 0.78478104, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "K = [50, 75, 100, 125, 150, 175, 200]\n",
    "nn50 = Sequential()\n",
    "nn75 = Sequential()\n",
    "nn100 = Sequential()\n",
    "nn125 = Sequential()\n",
    "nn150 = Sequential()\n",
    "nn175 = Sequential()\n",
    "nn200 = Sequential()\n",
    "nns = [nn50, nn75, nn100, nn125, nn150, nn175, nn200]\n",
    "results = []\n",
    "ind = 0;\n",
    "batch_size = 5000\n",
    "num_epochs = 10\n",
    "for k in K:\n",
    "    cur_nn = nns[ind]\n",
    "    ind = ind + 1\n",
    "    n_cols = k\n",
    "    x_tr, x_test, y_tr, y_test = split_with_PCA(k, train[cols], y)\n",
    "    cur_nn.add(Dense(300, activation='relu', input_shape=(n_cols,)))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(500, activation='relu'))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(100, activation='relu'))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(25, activation='relu'))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(1, activation='sigmoid'))\n",
    "    cur_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_accuracy'])\n",
    "    x_vl, y_vl = x_tr[:batch_size], y_tr[:batch_size]\n",
    "    x_train, y_train = x_tr[batch_size:], y_tr[batch_size:]\n",
    "    print(\"For k=\" + str(k))\n",
    "    cur_nn.fit(x_train, y_train, validation_data=(x_vl, y_vl), epochs=num_epochs, batch_size=batch_size)\n",
    "    res = cur_nn.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "    results.append(res)\n",
    "    print('test loss, test acc, categorical accuracy:', res)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      4169\n",
      "           1       0.76      0.72      0.74      4097\n",
      "\n",
      "    accuracy                           0.75      8266\n",
      "   macro avg       0.75      0.75      0.75      8266\n",
      "weighted avg       0.75      0.75      0.75      8266\n",
      "\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      4169\n",
      "           1       0.79      0.74      0.76      4097\n",
      "\n",
      "    accuracy                           0.77      8266\n",
      "   macro avg       0.77      0.77      0.77      8266\n",
      "weighted avg       0.77      0.77      0.77      8266\n",
      "\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.78      4169\n",
      "           1       0.80      0.71      0.75      4097\n",
      "\n",
      "    accuracy                           0.77      8266\n",
      "   macro avg       0.77      0.77      0.77      8266\n",
      "weighted avg       0.77      0.77      0.77      8266\n",
      "\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      4169\n",
      "           1       0.78      0.76      0.77      4097\n",
      "\n",
      "    accuracy                           0.77      8266\n",
      "   macro avg       0.77      0.77      0.77      8266\n",
      "weighted avg       0.77      0.77      0.77      8266\n",
      "\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79      4169\n",
      "           1       0.80      0.74      0.77      4097\n",
      "\n",
      "    accuracy                           0.78      8266\n",
      "   macro avg       0.78      0.78      0.78      8266\n",
      "weighted avg       0.78      0.78      0.78      8266\n",
      "\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      4169\n",
      "           1       0.81      0.74      0.78      4097\n",
      "\n",
      "    accuracy                           0.79      8266\n",
      "   macro avg       0.79      0.79      0.79      8266\n",
      "weighted avg       0.79      0.79      0.79      8266\n",
      "\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80      4169\n",
      "           1       0.83      0.71      0.77      4097\n",
      "\n",
      "    accuracy                           0.79      8266\n",
      "   macro avg       0.79      0.78      0.78      8266\n",
      "weighted avg       0.79      0.79      0.78      8266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "ind = 0\n",
    "for model in nns:\n",
    "    k = K[ind]\n",
    "    ind = ind + 1\n",
    "    _, x_test, _, y_test = split_with_PCA(k, train[cols], y)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(sklearn.metrics.classification_report(y_test, [round(y[0]) for y in y_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
