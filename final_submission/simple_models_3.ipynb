{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing, decomposition, model_selection, linear_model, metrics, ensemble, svm, utils\n",
    "from sklearn.datasets import make_classification\n",
    "import gc\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "train_transaction = pd.read_csv('data/train_transaction.csv')\n",
    "train_identity = pd.read_csv('data/train_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join datasets\n",
    "dataset = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce memory usage\n",
    "def reduce_mem(df):\n",
    "  start_mem=df.memory_usage().sum()/1024**2\n",
    "  print('Initial Memory Usage : {:.2f} MB'.format(start_mem))\n",
    "  for col in df.columns:\n",
    "    col_type=df[col].dtype\n",
    "    if col_type != object:\n",
    "      mn, mx = df[col].min(), df[col].max()\n",
    "      if str(col_type)[:3]=='int':\n",
    "        if mn>np.iinfo(np.int8).min and mx<np.iinfo(np.int8).max:\n",
    "          df[col]=df[col].astype(np.int8)\n",
    "        elif mn>np.iinfo(np.int16).min and mx<np.iinfo(np.int16).max:\n",
    "          df[col]=df[col].astype(np.int16)\n",
    "        elif mn>np.iinfo(np.int32).min and mx<np.iinfo(np.int32).max:\n",
    "          df[col]=df[col].astype(np.int32)\n",
    "      else:\n",
    "        if mn>np.finfo(np.float16).min and mx<np.finfo(np.float16).max:\n",
    "          df[col]=df[col].astype(np.float16)\n",
    "        elif mn>np.finfo(np.float32).min and mx<np.finfo(np.float32).max:\n",
    "          df[col]=df[col].astype(np.float32)\n",
    "  end_mem = df.memory_usage().sum()/1024**2\n",
    "  print('Final Memory Usage : {:.2f} MB'.format(end_mem))\n",
    "  print('Decreased by {:.2f}%'.format(100*(start_mem-end_mem)/start_mem))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Memory Usage : 1959.88 MB\n",
      "Final Memory Usage : 648.22 MB\n",
      "Decreased by 66.93%\n"
     ]
    }
   ],
   "source": [
    "dataset = reduce_mem(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_transaction, train_identity\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values\n",
    "dataset = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "for f in dataset.columns:\n",
    "    if dataset[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(dataset[f].values))\n",
    "        dataset[f] = lbl.transform(list(dataset[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.isFraud.values\n",
    "dataset = dataset.drop('isFraud',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "cols = list(dataset.columns)\n",
    "dataset[cols] = scaler.fit_transform(dataset[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8517370441936513\n"
     ]
    }
   ],
   "source": [
    "# Reduce number of dimensions through PCA\n",
    "N = 50\n",
    "svd = decomposition.TruncatedSVD(n_components=N, random_state=42)\n",
    "X = svd.fit_transform(dataset[cols])  \n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = ensemble.RandomForestClassifier(n_estimators=200,criterion='gini',n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = linear_model.LogisticRegression(C=1, solver=\"newton-cg\", penalty=\"l2\", n_jobs=-1, max_iter=200).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(max_iter=200).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.91      0.34      0.50      4134\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.94      0.67      0.74    118108\n",
      "weighted avg       0.97      0.98      0.97    118108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, random_forest_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    113974\n",
      "           1       0.81      0.15      0.25      4134\n",
      "\n",
      "    accuracy                           0.97    118108\n",
      "   macro avg       0.89      0.57      0.62    118108\n",
      "weighted avg       0.96      0.97      0.96    118108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, logistic_regression_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97    113974\n",
      "           1       0.02      0.01      0.02      4134\n",
      "\n",
      "    accuracy                           0.95    118108\n",
      "   macro avg       0.49      0.50      0.49    118108\n",
      "weighted avg       0.93      0.95      0.94    118108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, svm_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_param_grid = {}\n",
    "#rfc_param_grid = {'n_estimators':[25, 50, 100], 'criterion':('gini', 'entropy')}\n",
    "#svc_param_grid = {}\n",
    "\n",
    "#rfc = ensemble.RandomForestClassifier()\n",
    "#rfc_gs = GridSearchCV(rfc, rfc_param_grid, cv=10)\n",
    "#rfc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_with_PCA(k, x_tr, y):\n",
    "    X_PCA = decomposition.TruncatedSVD(n_components=k).fit_transform(x_tr)  \n",
    "    return model_selection.train_test_split(X_PCA, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=50\n",
      "Train on 467432 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1551 - accuracy: 0.9616 - categorical_accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9724 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.1197 - accuracy: 0.9700 - categorical_accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9730 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.1153 - accuracy: 0.9708 - categorical_accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9738 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.1125 - accuracy: 0.9713 - categorical_accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9738 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.1104 - accuracy: 0.9716 - categorical_accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9734 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.1087 - accuracy: 0.9719 - categorical_accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9738 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1078 - accuracy: 0.9722 - categorical_accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9736 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1062 - accuracy: 0.9726 - categorical_accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9754 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.1047 - accuracy: 0.9729 - categorical_accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9754 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1037 - accuracy: 0.9731 - categorical_accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9760 - val_categorical_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.80      0.33      0.47      4134\n",
      "\n",
      "    accuracy                           0.97    118108\n",
      "   macro avg       0.89      0.66      0.73    118108\n",
      "weighted avg       0.97      0.97      0.97    118108\n",
      "\n",
      "For k=75\n",
      "Train on 467432 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "467432/467432 [==============================] - 7s 14us/sample - loss: 0.1516 - accuracy: 0.9620 - categorical_accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9720 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1176 - accuracy: 0.9702 - categorical_accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9724 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1128 - accuracy: 0.9710 - categorical_accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9738 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "467432/467432 [==============================] - 6s 14us/sample - loss: 0.1097 - accuracy: 0.9715 - categorical_accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9750 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "467432/467432 [==============================] - 6s 14us/sample - loss: 0.1071 - accuracy: 0.9719 - categorical_accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9750 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1050 - accuracy: 0.9725 - categorical_accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9754 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1031 - accuracy: 0.9730 - categorical_accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9762 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1012 - accuracy: 0.9735 - categorical_accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9768 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0997 - accuracy: 0.9738 - categorical_accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9756 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0983 - accuracy: 0.9742 - categorical_accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9758 - val_categorical_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.84      0.36      0.50      4134\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.91      0.68      0.75    118108\n",
      "weighted avg       0.97      0.98      0.97    118108\n",
      "\n",
      "For k=100\n",
      "Train on 467432 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "467432/467432 [==============================] - 7s 14us/sample - loss: 0.1581 - accuracy: 0.9593 - categorical_accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9730 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1160 - accuracy: 0.9705 - categorical_accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9732 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1099 - accuracy: 0.9716 - categorical_accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9744 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1061 - accuracy: 0.9725 - categorical_accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9752 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1035 - accuracy: 0.9728 - categorical_accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9760 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1012 - accuracy: 0.9734 - categorical_accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9752 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0987 - accuracy: 0.9740 - categorical_accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9762 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0974 - accuracy: 0.9744 - categorical_accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9764 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0956 - accuracy: 0.9747 - categorical_accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9780 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0940 - accuracy: 0.9753 - categorical_accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9782 - val_categorical_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.85      0.38      0.53      4134\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.91      0.69      0.76    118108\n",
      "weighted avg       0.97      0.98      0.97    118108\n",
      "\n",
      "For k=125\n",
      "Train on 467432 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "467432/467432 [==============================] - 7s 15us/sample - loss: 0.1427 - accuracy: 0.9668 - categorical_accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9736 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1120 - accuracy: 0.9713 - categorical_accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9744 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1070 - accuracy: 0.9720 - categorical_accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9752 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1030 - accuracy: 0.9729 - categorical_accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9760 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "467432/467432 [==============================] - 7s 14us/sample - loss: 0.1002 - accuracy: 0.9735 - categorical_accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9770 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "467432/467432 [==============================] - 6s 14us/sample - loss: 0.0975 - accuracy: 0.9743 - categorical_accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9776 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0947 - accuracy: 0.9748 - categorical_accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9770 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0929 - accuracy: 0.9755 - categorical_accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9768 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "467432/467432 [==============================] - 6s 14us/sample - loss: 0.0909 - accuracy: 0.9758 - categorical_accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9784 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "467432/467432 [==============================] - 6s 14us/sample - loss: 0.0892 - accuracy: 0.9763 - categorical_accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9766 - val_categorical_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.89      0.39      0.54      4134\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.93      0.69      0.76    118108\n",
      "weighted avg       0.98      0.98      0.97    118108\n",
      "\n",
      "For k=150\n",
      "Train on 467432 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "467432/467432 [==============================] - 7s 14us/sample - loss: 0.1492 - accuracy: 0.9634 - categorical_accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9732 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1107 - accuracy: 0.9714 - categorical_accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9738 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1057 - accuracy: 0.9722 - categorical_accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9748 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1016 - accuracy: 0.9732 - categorical_accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9752 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0987 - accuracy: 0.9739 - categorical_accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9752 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0956 - accuracy: 0.9746 - categorical_accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9770 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0929 - accuracy: 0.9753 - categorical_accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9770 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0911 - accuracy: 0.9759 - categorical_accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9774 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0892 - accuracy: 0.9763 - categorical_accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9772 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0870 - accuracy: 0.9768 - categorical_accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9784 - val_categorical_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.86      0.41      0.56      4134\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.92      0.71      0.77    118108\n",
      "weighted avg       0.97      0.98      0.97    118108\n",
      "\n",
      "For k=175\n",
      "Train on 467432 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "467432/467432 [==============================] - 7s 15us/sample - loss: 0.1492 - accuracy: 0.9631 - categorical_accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9734 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1127 - accuracy: 0.9712 - categorical_accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9746 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "467432/467432 [==============================] - 7s 14us/sample - loss: 0.1064 - accuracy: 0.9724 - categorical_accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9744 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "467432/467432 [==============================] - 7s 14us/sample - loss: 0.1026 - accuracy: 0.9731 - categorical_accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9760 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0990 - accuracy: 0.9739 - categorical_accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9762 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0961 - accuracy: 0.9747 - categorical_accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9764 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0930 - accuracy: 0.9755 - categorical_accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9770 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0907 - accuracy: 0.9761 - categorical_accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9780 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0883 - accuracy: 0.9766 - categorical_accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9780 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0864 - accuracy: 0.9770 - categorical_accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9792 - val_categorical_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.85      0.42      0.56      4134\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.91      0.71      0.77    118108\n",
      "weighted avg       0.97      0.98      0.97    118108\n",
      "\n",
      "For k=200\n",
      "Train on 467432 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "467432/467432 [==============================] - 7s 15us/sample - loss: 0.1371 - accuracy: 0.9680 - categorical_accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9736 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1091 - accuracy: 0.9717 - categorical_accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9746 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.1032 - accuracy: 0.9726 - categorical_accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9752 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.0989 - accuracy: 0.9736 - categorical_accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9756 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.0953 - accuracy: 0.9744 - categorical_accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9770 - val_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "467432/467432 [==============================] - 6s 12us/sample - loss: 0.0927 - accuracy: 0.9752 - categorical_accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9776 - val_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0898 - accuracy: 0.9759 - categorical_accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9780 - val_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0870 - accuracy: 0.9767 - categorical_accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9782 - val_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0848 - accuracy: 0.9771 - categorical_accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9792 - val_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "467432/467432 [==============================] - 6s 13us/sample - loss: 0.0826 - accuracy: 0.9777 - categorical_accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9790 - val_categorical_accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    113974\n",
      "           1       0.84      0.45      0.58      4134\n",
      "\n",
      "    accuracy                           0.98    118108\n",
      "   macro avg       0.91      0.72      0.79    118108\n",
      "weighted avg       0.98      0.98      0.97    118108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# use PCA from sklearn instead?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "K = [50, 75, 100, 125, 150, 175, 200]\n",
    "nns = [Sequential() for _ in range(len(K))]\n",
    "results = []\n",
    "batch_size = 5000\n",
    "num_epochs = 10\n",
    "\n",
    "for k, cur_nn in zip(K, nns):\n",
    "    n_cols = k\n",
    "    x_tr, x_test, y_tr, y_test = split_with_PCA(k, dataset[cols], y)\n",
    "    cur_nn.add(Dense(300, activation='relu', input_shape=(n_cols,)))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(500, activation='relu'))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(100, activation='relu'))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(25, activation='relu'))\n",
    "    cur_nn.add(Dropout(0.2))\n",
    "    cur_nn.add(Dense(1, activation='sigmoid'))\n",
    "    cur_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'categorical_accuracy'])\n",
    "    x_vl, y_vl = x_tr[:batch_size], y_tr[:batch_size]\n",
    "    x_train, y_train = x_tr[batch_size:], y_tr[batch_size:]\n",
    "    print(\"For k=\" + str(k))\n",
    "    cur_nn.fit(x_train, y_train, validation_data=(x_vl, y_vl), epochs=num_epochs, batch_size=batch_size)\n",
    "    #res = cur_nn.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "    print(sklearn.metrics.classification_report(y_test, cur_nn.predict_classes(x_test)))\n",
    "    #results.append(res)\n",
    "    #print('test loss, test acc, categorical accuracy:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
